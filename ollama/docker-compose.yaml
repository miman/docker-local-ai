# If you need more help, visit the Docker Compose reference guide at
# https://docs.docker.com/go/compose-spec-reference/

services:
   ollama-container:
      image: ollama/ollama
      container_name: ollama
      networks:
         - local-ai-network
      ports:
         - "11434:11434"
      restart: always
      volumes:
         - ollama:/root/.ollama

   ollama-webui:
      image: ghcr.io/open-webui/open-webui:main
      container_name: ollama-open-webui
      networks:
         - local-ai-network
      ports:
         - "4512:8080"
      restart: always
      volumes:
         - open-webui:/app/backend/data
      extra_hosts:
         - "host.docker.internal:host-gateway"
      environment:
         - USE_OLLAMA_DOCKER=true

# We create a specific volume for the Docker container to store the files related to this container
volumes:
   ollama:
      external: true
   open-webui:
      external: true

# We create a specific network for these Docker containers to communicate over called local-ai-network
networks:
   local-ai-network:
      external: false
